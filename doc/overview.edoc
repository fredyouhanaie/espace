%% -*- mode:html -*-

@author Fred Youhanaie <fyrlang@anydata.co.uk>
@copyright 2017-2023 Fred Youhanaie
@version 0.8.0

@doc

<h3>Introduction</h3>

<p><code>espace</code> is an Erlang implementation of the Tuple Spaces
  (or Linda) paradigm. Details of the paradigm can be found on
  Wikipedia for
  <a href="https://en.wikipedia.org/wiki/Linda_(coordination_language)">Linda</a>
  and
  <a href="https://en.wikipedia.org/wiki/Tuple_space">Tuple Spaces</a>.
</p>

<p>Another good source that describes the paradigm well is the
  following paper:</p>

<blockquote>
  <p>Carriero, Nicholas &amp; Gelernter, David. (1989).<br />  How to
    Write Parallel Programs: A Guide to the Perplexed.<br />  ACM
    Computing Surveys. 21. 323-357.</p>
</blockquote>

<p><code>espace</code> allows one to implement parallel algorithms
  where tasks (worker processes) running concurrently communicate and
  coordinate through the tuple space.</p>

<p>The basic idea behind tuple spaces is that an application is given
  a storage pool where tuples are added to it via the <code>out</code>
  and <code>eval</code> operations, or taken from the pool via
  the <code>in/inp</code> and <code>rd/rdp</code> operations.</p>

<p>These six operations are all that is needed for communication and
  coordination among the concurrent processes.</p>

<p>An application that uses this system will have many concurrently active
  worker processes that look, and optionally, wait for tuples that match a
  desired pattern. The waiting workers will block until a matching tuple is
  added to the pool by another worker using the `out'/`eval' operations.</p>

<p>The worker processes are started via the `espace:worker/1,2' function. A
  worker can in turn start further workers by calling `worker/1,2'.</p>

<p>A typical application will start with a series of <code>out</code>
  and <code>eval</code> operations. Some of the worker processes will then, using
  the <code>in</code> or <code>rd</code> operations, pick the tuples added via
  the <code>out</code> operations, process them, then <code>out</code> the
  results. Other worker processes can then pick the results and process them
  further.</p>

<p>The implementation provides a space for the tuples, currently
  <code>ETS</code>, along with the six basic
  operations, <code>eval</code>,
  <code>out</code>, <code>in</code>, <code>inp</code>, <code>rd</code>
  and <code>rdp</code>.</p>

<h3><i>eval</i> <u>vs</u> <i>worker</i></h3>

<p>The `eval' operation behaves in the same way as `out', with the exception
  that if there are any `fun' expressions in the supplied tuple, they will be
  replaced with their respective function values before being added to the tuple
  space. The evaluation of the `fun' expression will be carried out in a
  separate process. Which makes `eval' the main method of starting concurrent
  processes.</p>

<p>Two forms of function elements are recognized: A zero arity `fun'
  expression,
  <code>eval({..., fun () -> expr end, ...})</code>
  or
  <code>eval({..., fun Fun_name/0, ...})</code>,
  and a tuple with two elements, an `N' arity `fun' expression together with a
  list of length `N',
  <code>eval({..., {fun (A, B, ...) -> expr end, [expr, expr, ...]}, ...})</code>
  or
  <code>eval({..., {fun Fun_name/N, [expr, expr, ...]}, ...})</code>.
  In the second form, the arity can be zero, however, an empty arg list, `[]',
  must accompany the function.</p>

<p>For example, <code>eval({sum, 2, 5, fun () 2+5 end})</code> will result in
  the tuple <code>{sum, 2, 5, 7}</code>. This has the same effect
  as <code>eval({sum, 2, 5, 2+5})</code>, however, the main difference is that
  in the former a new process will be created to evaluate the sum. The advantage
  of using `eval` is where the function(s) perform complex tasks, and we prefer
  to let the main client to continue its work while the computation is being
  carried out in the background.</p>

<p>The `worker/1,2' function is a convenient function to spawn new processes in
  the background. The return value of the function is discarded. Typically this
  is useful for long running processes that repeatedly wait for a tuple, process
  it and produce some output.</p>

<p>The `worker/1,2' function takes a tuple that is of the form `{Mod, Fun,
  [Args]}' or `fun' expression like those accepted by `eval/1,2'.</p>

<h3>Organization of the Project Modules</h3>

<p><code>espace</code> has been built as an OTP
  application, <code>espace_app</code>. Multiple instances of the application
  can run concurrently on the same node without interfering with each other.</p>

<p>The application server should be started with <code>espace:start/1,2</code>.
  Once the server is running, the client processes can use
  the <code>espace</code> module to perform any of the six operations. In fact,
  one can kick off the whole process by calling a purpose written bootstrap
  function, which can in turn perform <code>out</code> and <code>eval</code>
  operations.</p>

<p>The top level supervisor started by <code>espace_app</code>
  is <code>espace_sup</code>. This supervisor manages the
  three <code>gen_server</code>s, as described below:</p>

<ul>

  <li><code>etsmgr_srv</code> is a <code>gen_server</code> that adds resiliency
    to the ETS tables, should any of their owner servers restart due to some
    fault. A single instance of `etsmgr_srv' is used for managing the two ETS
    tables. You can find further details in
    the <a href="https://github.com/fredyouhanaie/etsmgr">project repo</a>.</li>

  <li><code>espace_tspace_srv</code> maintains the <code>espace_tspace</code>
    ETS table, the main tuple space pool. If a requested pattern does not exist
    and the request is a blocking one, i.e. <code>in</code> or <code>rd</code>,
    then the pattern is forwarded to <code>espace_tspatt_srv</code>. In case of
    an <code>out</code> request, the tuple is stored in the table,
    and <code>espace_tspatt_srv</code> is notified so that it can inform all the
    blocking clients whose requested pattern matches this tuple to retry
    the <i>in</i>/<i>rd</i> operation.</li>

  <li><code>espace_tspatt_srv</code> maintains the <code>espace_tspatt</code>
    ETS table, which contains the tuple patterns that worker processes (clients)
    are blocked on. It accepts two types of requests
    from <code>espace_tspace_srv</code>, one for adding unmatched patterns,
    which, along with the client details, are then added to
    the <code>espace_tspatt</code> table, and the other for the newly added
    tuples, which are matched against the existing patterns in the table and, if
    matched, notify the blocked clients to retry the `in'/`rd' operation.</li>

</ul>

<h4>The ETS Tables</h4>

<p>The tuples are kept in a pair of ETS tables, `espace_tspace' and
`espace_tspatt'.</p>

<p>The first table, <code>espace_tspace</code> has two columns, an integer, and
  the tuple itself. All access to the table is handled by a single
  server, <code>espace_tspace_srv</code>.</p>

<p>For the cases where no matching tuple is found for a given pattern, and the
  operation is a blocking one, i.e. `in' or `rd', a second ETS
  table <code>espace_tspatt</code> is used to remember the pattern, the client
  PID and a unique reference for this specific request. The unique reference
  will be used by the <code>espace</code> client side function to block on a
  receive for that reference.</p>

<p>Each <code>out</code> operation, after inserting the new tuple, will
  notify <code>espace_tspatt_srv</code> of the new
  tuple. <code>espace_tspatt_srv</code> will then scan the blocking clients
  whose pattern matches the newly added tuple. If a match is found, the waiting
  client is notified and the client entry is removed from the table.</p>

<p>Once the waiting client receives the notification, it will attempt
  the <code>rd</code> or <code>in</code> operation again. Note that the client
  is not handed the tuple, but notified to request it again. This waiting and
  the subsequent notification occurs inside the espace client code. If more than
  one client have waiting patterns that match the new tuple, then they may end
  up competing for it. However, since the ETS table is
  an <code>ordered_set</code>, the notification will be performed in a first
  come (blocked) first served (notified) manner. However, we cannot guarantee
  that the first unblocked client will get the tuple! This non-determinism is
  part of the original specification.</p>

<h4>The Operation Counters</h4>

<p>For each running instance of `espace' a set of counters are maintained. Each
  set consists of six counters, one for each `espace' operation. The counters
  are incremented whenever the operation is requested. Note that each `eval'
  will increment two counters, `eval' and `out'.</p>

<p>The functions for the operation of the counters are in the `espace_util'
  module and have the prefix `opcount_'. However, only two of them are meant for
  general use, `opcount_counts/0,1' and `opcount_reset/0,1'. The former will
  return a map of the operation/count pairs, while the latter will reset the
  counts to zero.</p>

<h4>The persistent term records</h4>

<p>In order to provide better visibility of the internal workings of an `espace'
  instance, as well as simplifying some of the code, a set of `persistent_term'
  records are maintained for each active instance.</p>

<p>The functions for manipulating the terms are in the `espace_util' module and
  are prefixed `pterm_'. The terms are created during the instance startup, and
  removed during the instance shutdown.</p>

<p>The keys are of the form `{espace, Inst :: atom(), Key :: atom()}', where
  `Inst' is the instance name, and `Key' specifies the particular term. The
  current keys are listed below:

<ol>

<li>`espace_sup', `espace_tspace_srv', `espace_tspatt_srv' and `etsmgr_srv'
  identify the registered server names.</li>

<li>`tspace_tabid' and `tspatt_tabid' contain the ETS table ids.</li>

<li>`opcounters' identifies the reference for the `counters' module.</li>

<li>`espace_tspace' and `espace_tspatt' identify the table names for the
  `etsmgr' instance.</li>

</ol>

</p>

@end
